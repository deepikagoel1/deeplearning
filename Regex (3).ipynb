{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regex.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-7QOIMbFTrC"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yORJvikGc9Eu",
        "outputId": "760840bd-dc66-43a0-e24d-7c27f041d9ce"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqYF6wxfdMr3"
      },
      "source": [
        "##Defining Model Architecture using sequential model\n",
        "\n",
        "model = tf.keras.Sequential([keras.layers.Dense(units = 1, input_shape = [1])])  "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKjXgfgue8oU",
        "outputId": "1eddb729-e951-43c5-eb00-0f1c7905bf02"
      },
      "source": [
        "model.summary()  ##To check the model architecture "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCNYZhHXfGZt"
      },
      "source": [
        "## What optimizers we are going to use and what loss we have to minimise\n",
        "\n",
        "##Compiling the model\n",
        "\n",
        "model.compile(optimizer = 'sgd', loss = 'mean_squared_error', metrics = ['accuracy'])\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sGAhiGQgWvu"
      },
      "source": [
        "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPFMxoVygpUd",
        "outputId": "563e8836-b156-4b3b-9838-f9b15c9c86fe"
      },
      "source": [
        "model.fit(xs, ys, epochs = 150)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 26.8626 - accuracy: 0.0000e+00\n",
            "Epoch 2/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 21.4331 - accuracy: 0.0000e+00\n",
            "Epoch 3/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 17.1553 - accuracy: 0.0000e+00\n",
            "Epoch 4/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.7837 - accuracy: 0.0000e+00\n",
            "Epoch 5/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.1252 - accuracy: 0.0000e+00\n",
            "Epoch 6/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.0278 - accuracy: 0.1667\n",
            "Epoch 7/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3721 - accuracy: 0.1667\n",
            "Epoch 8/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.0639 - accuracy: 0.1667\n",
            "Epoch 9/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0292 - accuracy: 0.1667\n",
            "Epoch 10/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2099 - accuracy: 0.1667\n",
            "Epoch 11/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5601 - accuracy: 0.1667\n",
            "Epoch 12/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0438 - accuracy: 0.1667\n",
            "Epoch 13/150\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6326 - accuracy: 0.1667\n",
            "Epoch 14/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3042 - accuracy: 0.1667\n",
            "Epoch 15/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0410 - accuracy: 0.1667\n",
            "Epoch 16/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8293 - accuracy: 0.1667\n",
            "Epoch 17/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6581 - accuracy: 0.1667\n",
            "Epoch 18/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5190 - accuracy: 0.1667\n",
            "Epoch 19/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4051 - accuracy: 0.1667\n",
            "Epoch 20/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3111 - accuracy: 0.1667\n",
            "Epoch 21/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2330 - accuracy: 0.1667\n",
            "Epoch 22/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1674 - accuracy: 0.1667\n",
            "Epoch 23/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1118 - accuracy: 0.1667\n",
            "Epoch 24/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0640 - accuracy: 0.1667\n",
            "Epoch 25/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0225 - accuracy: 0.1667\n",
            "Epoch 26/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9861 - accuracy: 0.1667\n",
            "Epoch 27/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9537 - accuracy: 0.1667\n",
            "Epoch 28/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9246 - accuracy: 0.1667\n",
            "Epoch 29/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8981 - accuracy: 0.1667\n",
            "Epoch 30/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8737 - accuracy: 0.1667\n",
            "Epoch 31/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8511 - accuracy: 0.1667\n",
            "Epoch 32/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8300 - accuracy: 0.1667\n",
            "Epoch 33/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8101 - accuracy: 0.1667\n",
            "Epoch 34/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7911 - accuracy: 0.1667\n",
            "Epoch 35/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7731 - accuracy: 0.1667\n",
            "Epoch 36/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7558 - accuracy: 0.1667\n",
            "Epoch 37/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7392 - accuracy: 0.1667\n",
            "Epoch 38/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7232 - accuracy: 0.1667\n",
            "Epoch 39/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7076 - accuracy: 0.1667\n",
            "Epoch 40/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6925 - accuracy: 0.1667\n",
            "Epoch 41/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6779 - accuracy: 0.1667\n",
            "Epoch 42/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6636 - accuracy: 0.1667\n",
            "Epoch 43/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6497 - accuracy: 0.1667\n",
            "Epoch 44/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6362 - accuracy: 0.1667\n",
            "Epoch 45/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6230 - accuracy: 0.1667\n",
            "Epoch 46/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6100 - accuracy: 0.1667\n",
            "Epoch 47/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5974 - accuracy: 0.1667\n",
            "Epoch 48/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5851 - accuracy: 0.1667\n",
            "Epoch 49/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5730 - accuracy: 0.1667\n",
            "Epoch 50/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5612 - accuracy: 0.1667\n",
            "Epoch 51/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5496 - accuracy: 0.1667\n",
            "Epoch 52/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5383 - accuracy: 0.1667\n",
            "Epoch 53/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.1667\n",
            "Epoch 54/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5163 - accuracy: 0.1667\n",
            "Epoch 55/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5057 - accuracy: 0.1667\n",
            "Epoch 56/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4953 - accuracy: 0.1667\n",
            "Epoch 57/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4851 - accuracy: 0.1667\n",
            "Epoch 58/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.1667\n",
            "Epoch 59/150\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.1667\n",
            "Epoch 60/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.1667\n",
            "Epoch 61/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.1667\n",
            "Epoch 62/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.1667\n",
            "Epoch 63/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4283 - accuracy: 0.1667\n",
            "Epoch 64/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.1667\n",
            "Epoch 65/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.1667\n",
            "Epoch 66/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.1667\n",
            "Epoch 67/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.1667\n",
            "Epoch 68/150\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3861 - accuracy: 0.1667\n",
            "Epoch 69/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.1667\n",
            "Epoch 70/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3704 - accuracy: 0.1667\n",
            "Epoch 71/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3628 - accuracy: 0.1667\n",
            "Epoch 72/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3553 - accuracy: 0.1667\n",
            "Epoch 73/150\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3480 - accuracy: 0.1667\n",
            "Epoch 74/150\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3409 - accuracy: 0.1667\n",
            "Epoch 75/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3339 - accuracy: 0.1667\n",
            "Epoch 76/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.1667\n",
            "Epoch 77/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3203 - accuracy: 0.1667\n",
            "Epoch 78/150\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3137 - accuracy: 0.1667\n",
            "Epoch 79/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3073 - accuracy: 0.1667\n",
            "Epoch 80/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.1667\n",
            "Epoch 81/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2948 - accuracy: 0.1667\n",
            "Epoch 82/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2887 - accuracy: 0.1667\n",
            "Epoch 83/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2828 - accuracy: 0.1667\n",
            "Epoch 84/150\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2770 - accuracy: 0.1667\n",
            "Epoch 85/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2713 - accuracy: 0.1667\n",
            "Epoch 86/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2657 - accuracy: 0.1667\n",
            "Epoch 87/150\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2603 - accuracy: 0.1667\n",
            "Epoch 88/150\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2549 - accuracy: 0.1667\n",
            "Epoch 89/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2497 - accuracy: 0.1667\n",
            "Epoch 90/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2446 - accuracy: 0.1667\n",
            "Epoch 91/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2395 - accuracy: 0.1667\n",
            "Epoch 92/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2346 - accuracy: 0.1667\n",
            "Epoch 93/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2298 - accuracy: 0.1667\n",
            "Epoch 94/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2251 - accuracy: 0.1667\n",
            "Epoch 95/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2205 - accuracy: 0.1667\n",
            "Epoch 96/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2159 - accuracy: 0.1667\n",
            "Epoch 97/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2115 - accuracy: 0.1667\n",
            "Epoch 98/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2071 - accuracy: 0.1667\n",
            "Epoch 99/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2029 - accuracy: 0.1667\n",
            "Epoch 100/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1987 - accuracy: 0.1667\n",
            "Epoch 101/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1946 - accuracy: 0.1667\n",
            "Epoch 102/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1906 - accuracy: 0.1667\n",
            "Epoch 103/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1867 - accuracy: 0.1667\n",
            "Epoch 104/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1829 - accuracy: 0.1667\n",
            "Epoch 105/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1791 - accuracy: 0.1667\n",
            "Epoch 106/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1755 - accuracy: 0.1667\n",
            "Epoch 107/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1719 - accuracy: 0.1667\n",
            "Epoch 108/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1683 - accuracy: 0.1667\n",
            "Epoch 109/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1649 - accuracy: 0.1667\n",
            "Epoch 110/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1615 - accuracy: 0.1667\n",
            "Epoch 111/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1582 - accuracy: 0.1667\n",
            "Epoch 112/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1549 - accuracy: 0.1667\n",
            "Epoch 113/150\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1517 - accuracy: 0.1667\n",
            "Epoch 114/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1486 - accuracy: 0.1667\n",
            "Epoch 115/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1456 - accuracy: 0.1667\n",
            "Epoch 116/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1426 - accuracy: 0.1667\n",
            "Epoch 117/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1396 - accuracy: 0.1667\n",
            "Epoch 118/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1368 - accuracy: 0.1667\n",
            "Epoch 119/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1340 - accuracy: 0.1667\n",
            "Epoch 120/150\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1312 - accuracy: 0.1667\n",
            "Epoch 121/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1285 - accuracy: 0.1667\n",
            "Epoch 122/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1259 - accuracy: 0.1667\n",
            "Epoch 123/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1233 - accuracy: 0.1667\n",
            "Epoch 124/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1208 - accuracy: 0.1667\n",
            "Epoch 125/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1183 - accuracy: 0.1667\n",
            "Epoch 126/150\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1159 - accuracy: 0.1667\n",
            "Epoch 127/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1135 - accuracy: 0.1667\n",
            "Epoch 128/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1111 - accuracy: 0.1667\n",
            "Epoch 129/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1089 - accuracy: 0.1667\n",
            "Epoch 130/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1066 - accuracy: 0.1667\n",
            "Epoch 131/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1044 - accuracy: 0.1667\n",
            "Epoch 132/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1023 - accuracy: 0.1667\n",
            "Epoch 133/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1002 - accuracy: 0.1667\n",
            "Epoch 134/150\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0981 - accuracy: 0.1667\n",
            "Epoch 135/150\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0961 - accuracy: 0.1667\n",
            "Epoch 136/150\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0941 - accuracy: 0.1667\n",
            "Epoch 137/150\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0922 - accuracy: 0.1667\n",
            "Epoch 138/150\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0903 - accuracy: 0.1667\n",
            "Epoch 139/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0885 - accuracy: 0.1667\n",
            "Epoch 140/150\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0866 - accuracy: 0.1667\n",
            "Epoch 141/150\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0849 - accuracy: 0.1667\n",
            "Epoch 142/150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.1667\n",
            "Epoch 143/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0814 - accuracy: 0.1667\n",
            "Epoch 144/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0797 - accuracy: 0.1667\n",
            "Epoch 145/150\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0781 - accuracy: 0.1667\n",
            "Epoch 146/150\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0765 - accuracy: 0.1667\n",
            "Epoch 147/150\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0749 - accuracy: 0.1667\n",
            "Epoch 148/150\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0734 - accuracy: 0.1667\n",
            "Epoch 149/150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0719 - accuracy: 0.1667\n",
            "Epoch 150/150\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0704 - accuracy: 0.1667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f13b48850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9mtyfoqg1Z9",
        "outputId": "dd32d81d-8f76-4ac5-a152-90659606c777"
      },
      "source": [
        "print(model.predict([10.0]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[18.225876]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWFHZx8Phf2l"
      },
      "source": [
        "###Taking fashion dataset\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWH1_hNxjshm",
        "outputId": "13de55d4-6ef7-40f2-98b3-4eafc557e855"
      },
      "source": [
        "(training_images, training_labels),(test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCxONCOnj1ba",
        "outputId": "4904962b-4ff6-4ca5-c0ac-96e0c137686d"
      },
      "source": [
        "print(training_images.shape)\n",
        "print(test_images.shape)\n",
        "print(training_labels.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "(60000,)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "8qaSQGXKkQpt",
        "outputId": "ea3d2751-e84a-4419-cf96-2d79009e608b"
      },
      "source": [
        "##how image represents in a matrix format\n",
        "\n",
        "##imshow takes a matrix format and shows an image.\n",
        "\n",
        "np.set_printoptions(linewidth = 300)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[0])\n",
        "print(training_labels[0])\n",
        "print(training_images[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUmMe373lFI8"
      },
      "source": [
        "##Normalizing the datasets\n",
        "\n",
        "training_images = training_images / 255\n",
        "\n",
        "test_images = test_images / 255"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enbkBVWFl5W4"
      },
      "source": [
        "model = tf.keras.Sequential([tf.keras.layers.Flatten(), \n",
        "                             tf.keras.layers.Dense(128, activation = tf.nn.relu),\n",
        "                             tf.keras.layers.Dense(10, tf.nn.softmax)])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZtngeixpBnn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvFCk6-tnWNh"
      },
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWylaaScnZNf",
        "outputId": "c53135a8-24d7-42b6-e75e-6740bf12d08d"
      },
      "source": [
        "model.fit(training_images, training_labels, epochs = 10)  #batch_size =>> At each step, we are providing 32 steps per epoch.\n",
        "#by default batch_size is 32"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6334 - accuracy: 0.7779\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3901 - accuracy: 0.8617\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3380 - accuracy: 0.8781\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3169 - accuracy: 0.8832\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2907 - accuracy: 0.8931\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2799 - accuracy: 0.8968\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2697 - accuracy: 0.9004\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2567 - accuracy: 0.9033\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2470 - accuracy: 0.9079\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2388 - accuracy: 0.9092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f1201df10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH-ZvGFOoOOs",
        "outputId": "9890fa0a-c34c-4dc4-cd8e-2e8302b62492"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (32, 784)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (32, 128)                 100480    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (32, 10)                  1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcRFF7ytolmy",
        "outputId": "12854566-8329-4513-aa96-0dc1485e40d7"
      },
      "source": [
        "128 * 785 #(28*28 = 784 ) + 1 for bias"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100480"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjfZH7SPpoko",
        "outputId": "932de29a-0d33-41db-b49f-2b6b6a912de3"
      },
      "source": [
        "1875 * 32 ##1875 is the number of steps it takes all 60000 for 1 epoch for 32 batch size"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9O92F7Ip6ja",
        "outputId": "081a9c01-5766-4232-8eb7-277f1dc0d48f"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3403 - accuracy: 0.8790\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34027886390686035, 0.8790000081062317]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC17U8UsqBUb"
      },
      "source": [
        "#785 (784+bias) *128 --> 100480 ( params) in the hideen layer\n",
        "#129(each neuron+bias) *10 == 1290"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH-WuUkErhcF"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels),(test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXNVfRePru5R"
      },
      "source": [
        "training_images = training_images.reshape(60000, 28, 28, 1)\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "\n",
        "training_images = training_images / 255\n",
        "test_images = test_images / 255"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_F3T2gisSjt"
      },
      "source": [
        "model = tf.keras.models.Sequential([ \n",
        "                                    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = (28, 28, 1)),\n",
        "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
        "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "                                    tf.keras.layers.Dense(10, activation = 'softmax')\n",
        "])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnLZCVzuuYBv"
      },
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA7Jk6TYunxU",
        "outputId": "5cdf3fa1-3f1f-4747-d9a2-c958e15b7e5c"
      },
      "source": [
        "model.fit(training_images, training_labels, epochs = 5)  #batch_size =>> At each step, we are providing 32 steps per epoch.\n",
        "#by default batch_size is 32"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 39s 6ms/step - loss: 0.6034 - accuracy: 0.7794\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3059 - accuracy: 0.8878\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2515 - accuracy: 0.9081\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2117 - accuracy: 0.9210\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1888 - accuracy: 0.9279\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4f11e5ae90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT7T-5duuuna",
        "outputId": "2fc72027-6aaf-484b-f79e-cca52c39a9f1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-W9ZMMJvPzJ",
        "outputId": "33fb733d-67de-49c7-9502-ca6549c83a3b"
      },
      "source": [
        "model.evaluate(test_images,test_labels)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2553 - accuracy: 0.9078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.25526586174964905, 0.907800018787384]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8OLEgsPv3Uo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}